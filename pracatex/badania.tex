


\chapter{Przeprowadzone badania}
\section{Projekt klasyfikatora}

\section{Opis platformy i w jaki sposób zrealizowano badania}

\subsection{Język python}
Wszystkie badania i testy zostały napisane z wykorzystaniem języka python. Jest to język programowania interpretowany, wysokiego poziomu z dużą ilością dostępnych bibliotek. Python\cite{python} posiada dynamiczne zarządzanie typami oraz automatyczne zarządzanie pamięcią. Wspiera kilka paradygmatów programowania, takich ja: obiektowy, imperatywny, funkcyjny i proceduralny. Został zaprojektowany z myślą o czytelności kodu oraz składnią pozwalającą napisać program z mniejszą ilością kodu niż w językach C++ lub Java. Implementacje języka python dostępna jest na wiele systemów operacyjnych. Często wykorzystywany jest jako język skryptowy. Python jest projektem typu Open Source. \par
W pracy wykorzystano język python w wersji 2.7.11. Język ten wybrano ze względu na łatwość pisania w nim kodu, szybką możliwość nauki oraz na szeroki wachlarz dostępnych bibliotek. Ważnym argumentem w wyborze były gotowe biblioteki z klasyfikatorami oraz do pracy z klasyfikacją danych. Dostępność bibliotek do wizualizacji dla tego języka, pozwoliła na przedstawienie wyników testów w formie graficznej. Napisane testy, można w łatwy sposób rozbudować, zmodyfikować lub dodać nowe elementy.    

\subsection{Biblioteka scikit-learn}
Scikit-learn\cite{scikit} to proste i wydajne narzędzie do analizy i eksploracji danych. Jest to biblioteka uczenia maszynowego dla języka python. Rozpowszechnianie oparta jest na licencji BSD. W Scikt-learn zaimplementowane są (lub napisany jest kod obsługujący) różne algorytmy klasyfikacji, regresji, analizy skupień takie jak: maszyna wektorów nośnych, algorytmy najbliższego sąsiada, naiwny Bayes, drzewa decyzyjne, sieć neuronowa, zespoły klasyfikatorów. Z wykorzystaniem tej biblioteki można przygotować oraz przetworzyć odpowiednio dane. Możliwe jest także, ocenianie i wizualizacja wyników. \par
W testach użyto biblioteki scikit-learn w wersji 0.18.1. Wykorzystano z niej algorytmy klasyfikacji oraz wstępnego przetwarzania danych.
\subsection{Biblioteka imbalanced-learn}
Biblioteka imbalanced-learn\cite{imlearn} zawiera zestaw narzędzi do wstępnego przetwarzania danych niezrównoważonych. Posiada ona zaimplementowane różne metody under- oraz over-sampling do równoważenia zbiorów danych. W pracy wykorzystano te metody z biblioteki w wersji 0.2.1. 
\subsection{Pozostałe użyte biblioteki}
\subsubsection{Mlxtend}
Mlxtend (machine learning extensions)\cite{mlxtend} jest to biblioteka zawierająca różne narzędzia do pracy z danymi. W badaniach wykorzystano z niej algorytm Stacking.
\subsubsection{Numpy}
Numpy to pakiet umożliwiający obliczenia naukowe. Szczególnym elementem jest możliwość wykonywania obliczeń na tablicach N-wymiarowych. 
\subsubsection{Maptolib}
Maptolib to biblioteka pythona, która tworzy różnego rodzaju wykresy 2D oraz interaktywne na różnych platformach.
\subsubsection{Texttable}
Texttable to prosty moduł napisany w języku python, służący do produkcji prostych tabel ASCII. Został wykorzystany do prezentacji wyników w konsoli.
\subsubsection{Pylatex}
Pylatex to biblioteka pythona, służąca do tworzenia i kompilacji plików LaTeX. W pracy została wykorzystana do zapisu wyników w badań w plikach .tex oraz .pdf.
\subsection{opisac co zaimplementowane?}
\todo{ze wlasna krosswalidacja, ze wlasne miary, klasyfikator. itd}

\todo{inline} napisac o roznych F i o tym jak wyniki wyglada, pokazać test

\section{Opis danych użytych w badaniach}
Do przeprowadzenia badań użyto 26 różnych prawdziwych zbiorów danych (tabela \ref{danebadania}) pochodzących z repozytorium serwisu "The UCI Machine Learning Repository" \cite{uci}. Dane wybrano ze względu na różnorodność typów danych, ilości rekordów, atrybutów oraz zróżnicowanie rozkładu klas. Większość z danych była używana w publikacjach podobnych tematycznie\cite{hyper}\cite{StefImbalanced}. \par
Wszystkie dane zostały zapisane w skrypcie, w folderze $praca/data/files$, a opis szczegółowy danych znajduje się w folderze $praca/data/files/data\_descrytpion$. Do importu danych służą funkcje z pliku $praca/data/import\_data.py$. Do ogólnego importu danych z pliku, służy funkcja $importfile$, zaś wczytywanie danych użytych w projekcie odbywa się poprzez funkcje zaczynające się od $load\_$. Import danych z pliku odbywa się z wykorzystaniem funkcji z pakietu $numpy$ $genfromtext$ oraz $load\_txt$. Atrybuty posiadające dane kategoryczne zapisane w postaci łańcuchów znaków zostały zamienione na dane numeryczne. Cechy nominalne zostały zakodowane metodą $one hot encoding$. Dla danych zawierających więcej niż dwie klasy, klasa z najmniejszą liczebnością została wybrana jako klasa mniejszościowa, pozostałe klasy utworzyły klasę większościową. We wszystkich zbiorach danych, kategorie reprezentowane są w systemie binarnym. 5 zbiorów danych posiadało brakujące wartości. Zostały one zastąpione wartościami środkowymi zbioru (medianą).
\begin{table}[h]
	\begin{center}
		\resizebox{\textwidth}{!}{%
			\begin{tabular}{|c|c|c|c|c|c|}%
				\hline%
				Nazwa danych&L. el.&Atrybuty&Rozklad klas&\% kl. mn.&IR\\%
				\hline%
				abalone0\_4&4177&8&4103/74&1.77&55.45\\%
				abalone041629&4177&8&3842/335&8.02&11.47\\%
				abalone16\_29&4177&8&3916/261&6.25&15.0\\%
				balance\_scale&625&4&576/49&7.84&11.76\\%
				breast\_cancer&286&9&201/85&29.72&2.36\\%
				bupa&341&6&200/141&41.35&1.42\\%
				car&1728&6&1663/65&3.76&25.58\\%
				cmc&1473&9&1140/333&22.61&3.42\\%
				ecoli&336&7&301/35&10.42&8.6\\%
				german&1000&24&700/300&30.0&2.33\\%
				glass&214&9&197/17&7.94&11.59\\%
				haberman&306&3&225/81&26.47&2.78\\%
				heart\_cleveland&303&13&268/35&11.55&7.66\\%
				hepatitis&155&19&123/32&20.65&3.84\\%
				horse\_colic&368&22&232/136&36.96&1.71\\%
				ionosphere&351&34&225/126&35.9&1.79\\%
				new\_thyroid&215&5&185/30&13.95&6.17\\%
				postoperative&90&8&66/24&26.67&2.75\\%
				seeds&210&7&140/70&33.33&2.0\\%
				solar\_flare&1066&10&1023/43&4.03&23.79\\%
				transfusion&748&4&569/179&23.93&3.18\\%
				vehicle&846&18&647/199&23.52&3.25\\%
				vertebal&310&6&210/100&32.26&2.1\\%
				yeastME1&1484&8&1440/44&2.96&32.73\\%
				yeastME2&1484&8&1433/51&3.44&28.1\\%
				yeastME3&1484&8&1321/163&10.98&8.1\\%
				\hline%
			\end{tabular}}
			\caption{Dane użyte w badaniach wraz z charakterystyką.}
			\label{danebadania}
		\end{center}
	\end{table}

\section{Sposób mierzenia w sprawdzianie krzyżowym}
\section{Ocena klasyfikatora w sprawdzianie krzyżowym k-krotnym.}
W większości publikacji naukowych dotyczących klasyfikacji, ocena klasyfikatora mierzona jest z wykorzystaniem sprawdzianu krzyżowego (zwykle k=10) oraz przedstawionych wcześniej miar. Jednakże, w tych publikacjach nie został opisany sposób obliczania współczynników w czasie sprawdzianu krzyżowego. Wykorzystanie różnych sposobów, prowadzi do różnych wyników. Niektóre metody są mniej lub bardziej obciążone błędem. Różnice w wynikach, wynikające z przyjętej metody obliczeniowej, są szczególnie widoczne w sprawdzianie krzyżowym z losowym rozkładem danych oraz w klasyfikacji danych niezrównoważonych. Są dwie główne możliwości obliczania współczynników:
\begin{itemize}
	\item obliczanie wartości współczynników dla każdej k-iteracji (klasyfikatora), a następnie obliczenie średniej z tych iteracji
	\item stworzenie jednej wspólnej macierzy pomyłek dla każdej k-iteracji, a następnie obliczenie wskaźników.
\end{itemize}
W przypadku drugiego sposobu, poszczególne elementy macierzy pomyłek będą wynosić odpowiednio:
\[TP := \sum_{i=1}^{k} TP^{(i)}\]
\[FP := \sum_{i=1}^{k} FP^{(i)}\]
\[TN := \sum_{i=1}^{k} TN^{(i)}\]
\[FN := \sum_{i=1}^{k} FN^{(i)}\]
\subsubsection{Dokładność oraz błąd klasyfikatora}
Dokładność klasyfikacji oraz błąd klasyfikatora, korzystając ze metody pierwszej, będzie wynosić:
\[accuracy_{avg} := \frac{1}{k} \sum_{i=1}^{k} accuracy^{(i)}\]
a błąd klasyfikatora:
\[error\ rate_{avg} = 1 - accuracy_{avg}\]
Obliczając drugim sposobem, korzysta się z podstawowego wzoru z wykorzystaniem wspólnej macierzy pomyłek. \par
W przypadku dokładności oraz błędu klasyfikatora, niezależnie od przyjętej metodyki otrzymane wartości będą takie same, nieobciążone błędem.
\subsubsection{Czułość, specyficzność, FPR oraz precyzja}
\[Sensitivity_{avg},\ Recall_{avg},\ TPR_{avg} := \sum_{i=1}^{k} TPR_{avg}^{(i)}\]
\[Specificity_{avg},\ TNR_{avg} := \sum_{i=1}^{k} TNR_{avg}^{(i)}\]
\[FPR_{avg} := \sum_{i=1}^{k} FPR_{avg}^{(i)}\]
\[Precision_{avg} := \sum_{i=1}^{k} Precision_{avg}^{(i)}\]
\subsubsection{Miara $F_1$}

\[F_{tp, fp, fn} = \frac{2*TP}{2*TP+FP+FN} \]
\[Pre_{avg} := \frac{1}{k} \sum_{i=1}^{k} Pre^{(i)}\]
\[Re_{avg} := \frac{1}{k} \sum_{i=1}^{k} Re^{(i)}\]
\[F_{pre, re} = 2 * \frac{Pre_{avg}*Re_{avg}}{Pre_{avg}+Re_{avg}} \]

\[F_{avg} := \frac{1}{k} \sum_{i=1}^{k} F_1^{(i)}\]

\subsubsection{Miara G-mean}
\[G-mean_{tp, fp, fn} = \sqrt{\frac{TP}{TP + FN}*\frac{TN}{TN + FP}} \]
\[G-mean_{Se, Sp} = \sqrt{Sensitivity_{avg}*Specificity_{avg}} \]
\[G-mean_{avg} := \frac{1}{k} \sum_{i=1}^{k} G-mean^{(i)} \]
\subsubsection{Krzywa ROC i miara AUC}
\section{Sprawdzian krzyżowy, a oversampling}

\section{Porównanie klasyfikatorów}
\todo{przetestsowa wszystkie klasyfkatory, z metodami pre i bez}

Porównanie klasyfikatorów z domyślnymi ustawieniami, na takich samych typach danych. Jeżeli w tabelce występuje 0, to klasyfikator całkowicie błędnie klasyfikuje klasę mniejszościową.
\begin{table}[h]
	\begin{center}
		\resizebox{\textwidth}{!}{%
			\begin{tabular}{|c|c|c|c|c|c|c|c|c|}%
				\hline%
				&Drzewo&kNN&NKB&SVM&RForest&BAGGING&BOOSTING&STACKING\\%
				\hline%
				abalone0\_4&0.98&0.99&0.96&0.98&0.99&0.96&0.96&0.99\\%
				\hline%
				abalone0\_4\_16\_29&0.89&0.92&0.87&0.92&0.93&0.87&0.71&0.92\\%
				\hline%
				abalone16\_29&0.9&0.93&0.7&0.94&0.94&0.71&0.66&0.94\\%
				\hline%
				balance\_scale&0.86&0.91&0.92&0.92&0.91&0.92&0.92&0.92\\%
				\hline%
				breast\_cancer&0.62&0.64&0.73&0.66&0.71&0.72&0.37&0.7\\%
				\hline%
				bupa&0.65&0.64&0.53&0.58&0.71&0.55&0.52&0.64\\%
				\hline%
				car&0.99&0.97&0.88&0.98&0.98&0.89&0.98&0.99\\%
				\hline%
				cmc&0.7&0.75&0.68&0.77&0.76&0.68&0.63&0.77\\%
				\hline%
				ecoli&0.89&0.9&0.77&0.9&0.92&0.78&0.93&0.9\\%
				\hline%
				german&0.68&0.69&0.73&0.72&0.77&0.71&0.68&0.73\\%
				\hline%
				glass&0.89&0.9&0.45&0.92&0.92&0.49&0.85&0.92\\%
				\hline%
				haberman&0.58&0.71&0.75&0.71&0.67&0.76&0.63&0.75\\%
				\hline%
				heart\_cleveland&0.8&0.88&0.8&0.88&0.87&0.8&0.78&0.88\\%
				\hline%
				hepatitis&0.78&0.75&0.77&0.79&0.83&0.75&0.55&0.81\\%
				\hline%
				horse\_colic&0.79&0.72&0.79&0.68&0.86&0.79&0.61&0.82\\%
				\hline%
				ionosphere&0.87&0.83&0.88&0.94&0.93&0.89&0.78&0.92\\%
				\hline%
				new\_thyroid&0.97&0.97&0.97&0.86&0.98&0.97&0.97&0.97\\%
				\hline%
				postoperative&0.61&0.63&0.72&0.73&0.64&0.68&0.38&0.71\\%
				\hline%
				seeds&0.9&0.93&0.92&0.95&0.92&0.92&0.9&0.93\\%
				\hline%
				solar\_flare&0.94&0.95&0.67&0.96&0.94&0.67&0.52&0.96\\%
				\hline%
				transfusion&0.62&0.67&0.74&0.7&0.66&0.74&0.64&0.72\\%
				\hline%
				vehicle&0.94&0.93&0.66&0.77&0.97&0.67&0.75&0.93\\%
				\hline%
				vertebal&0.79&0.82&0.78&0.68&0.82&0.77&0.71&0.81\\%
				\hline%
				yeastME1&0.98&0.98&0.66&0.97&0.98&0.7&0.92&0.98\\%
				\hline%
				yeastME2&0.94&0.96&0.17&0.97&0.97&0.17&0.1&0.96\\%
				\hline%
				yeastME3&0.93&0.95&0.32&0.89&0.95&0.29&0.89&0.94\\%
				\hline%
			\end{tabular}}%
			\caption{Dokładność algorytmów}
			\label{tab1}
		\end{center}
	\end{table}
	
	\begin{table}[h]
		\begin{center}
			\resizebox{\textwidth}{!}{%
				\begin{tabular}{|c|c|c|c|c|c|c|c|c|}%
					\hline%
					&Drzewo&kNN&NKB&SVM&RForest&BAGGING&BOOSTING&STACKING\\%
					\hline%
					abalone0\_4&0.43&0.58&0.97&0.0&0.51&0.97&0.42&0.42\\%
					\hline%
					abalone0\_4\_16\_29&0.36&0.25&0.3&0.0&0.23&0.29&0.28&0.16\\%
					\hline%
					abalone16\_29&0.29&0.15&0.59&0.0&0.13&0.57&0.45&0.08\\%
					\hline%
					balance\_scale&0.08&0.0&0.0&0.0&0.0&0.0&0.0&0.0\\%
					\hline%
					breast\_cancer&0.41&0.2&0.45&0.07&0.38&0.44&0.6&0.24\\%
					\hline%
					bupa&0.6&0.46&0.77&0.0&0.52&0.78&0.48&0.45\\%
					\hline%
					car&0.92&0.62&1.0&0.77&0.71&1.0&0.82&0.92\\%
					\hline%
					cmc&0.34&0.29&0.6&0.15&0.28&0.6&0.35&0.15\\%
					\hline%
					ecoli&0.6&0.46&0.94&0.0&0.49&0.94&0.63&0.4\\%
					\hline%
					german&0.51&0.32&0.62&0.13&0.41&0.64&0.01&0.18\\%
					\hline%
					glass&0.41&0.12&0.76&0.0&0.06&0.71&0.12&0.0\\%
					\hline%
					haberman&0.32&0.35&0.21&0.01&0.25&0.25&0.2&0.17\\%
					\hline%
					heart\_cleveland&0.23&0.0&0.57&0.0&0.0&0.51&0.31&0.0\\%
					\hline%
					hepatitis&0.53&0.06&0.72&0.0&0.5&0.69&0.56&0.31\\%
					\hline%
					horse\_colic&0.73&0.57&0.76&0.25&0.76&0.76&0.56&0.64\\%
					\hline%
					ionosphere&0.8&0.56&0.74&0.84&0.87&0.76&0.73&0.83\\%
					\hline%
					new\_thyroid&0.9&0.77&0.87&0.0&0.9&0.87&0.8&0.83\\%
					\hline%
					postoperative&0.21&0.0&0.12&0.0&0.0&0.12&0.62&0.0\\%
					\hline%
					seeds&0.89&0.94&0.94&0.94&0.9&0.94&0.9&0.91\\%
					\hline%
					solar\_flare&0.14&0.0&0.93&0.0&0.07&0.93&0.56&0.0\\%
					\hline%
					transfusion&0.24&0.27&0.17&0.06&0.27&0.18&0.34&0.1\\%
					\hline%
					vehicle&0.85&0.88&0.83&0.01&0.95&0.83&0.74&0.81\\%
					\hline%
					vertebal&0.66&0.76&0.88&0.0&0.73&0.85&0.61&0.7\\%
					\hline%
					yeastME1&0.68&0.66&1.0&0.0&0.64&1.0&0.55&0.55\\%
					\hline%
					yeastME2&0.33&0.14&0.96&0.0&0.14&0.96&0.94&0.0\\%
					\hline%
					yeastME3&0.68&0.68&0.98&0.0&0.66&0.98&0.03&0.61\\%
					\hline%
				\end{tabular}}%
				\caption{Specyficzność algorytmów}
				\label{tab}
			\end{center}
		\end{table}
		
		\begin{table}[h]
			\begin{center}
				\resizebox{\textwidth}{!}{%
					\begin{tabular}{|c|c|c|c|c|c|c|c|c|}%
						\hline%
						&Drzewo&kNN&NKB&SVM&RForest&BAGGING&BOOSTING&STACKING\\%
						\hline%
						abalone0\_4&0.66&0.76&0.97&0.0&0.71&0.97&0.64&0.65\\%
						\hline%
						abalone0\_4\_16\_29&0.58&0.49&0.52&0.0&0.48&0.52&0.46&0.4\\%
						\hline%
						abalone16\_29&0.52&0.38&0.65&0.0&0.36&0.64&0.55&0.28\\%
						\hline%
						balance\_scale&0.27&0.0&0.0&0.0&0.0&0.0&0.0&0.0\\%
						\hline%
						breast\_cancer&0.54&0.41&0.61&0.25&0.57&0.6&0.41&0.46\\%
						\hline%
						bupa&0.64&0.59&0.53&0.0&0.66&0.56&0.52&0.59\\%
						\hline%
						car&0.96&0.78&0.94&0.87&0.84&0.94&0.9&0.96\\%
						\hline%
						cmc&0.52&0.51&0.65&0.38&0.5&0.65&0.5&0.38\\%
						\hline%
						ecoli&0.75&0.66&0.84&0.0&0.69&0.85&0.78&0.62\\%
						\hline%
						german&0.62&0.52&0.69&0.36&0.62&0.69&0.1&0.42\\%
						\hline%
						glass&0.62&0.34&0.57&0.0&0.24&0.58&0.33&0.0\\%
						\hline%
						haberman&0.47&0.54&0.45&0.11&0.45&0.48&0.4&0.41\\%
						\hline%
						heart\_cleveland&0.45&0.0&0.69&0.0&0.0&0.65&0.51&0.0\\%
						\hline%
						hepatitis&0.67&0.24&0.75&0.0&0.68&0.72&0.55&0.54\\%
						\hline%
						horse\_colic&0.77&0.68&0.78&0.48&0.84&0.78&0.6&0.77\\%
						\hline%
						ionosphere&0.85&0.74&0.84&0.91&0.92&0.86&0.77&0.89\\%
						\hline%
						new\_thyroid&0.94&0.88&0.93&0.0&0.94&0.93&0.89&0.91\\%
						\hline%
						postoperative&0.4&0.0&0.34&0.0&0.0&0.33&0.42&0.0\\%
						\hline%
						seeds&0.89&0.94&0.92&0.95&0.91&0.92&0.9&0.93\\%
						\hline%
						solar\_flare&0.37&0.0&0.78&0.0&0.26&0.78&0.54&0.0\\%
						\hline%
						transfusion&0.42&0.46&0.4&0.22&0.46&0.41&0.5&0.3\\%
						\hline%
						vehicle&0.91&0.91&0.71&0.1&0.97&0.72&0.75&0.88\\%
						\hline%
						vertebal&0.75&0.8&0.8&0.0&0.8&0.79&0.68&0.77\\%
						\hline%
						yeastME1&0.82&0.81&0.81&0.0&0.8&0.83&0.71&0.74\\%
						\hline%
						yeastME2&0.57&0.37&0.36&0.0&0.37&0.37&0.26&0.0\\%
						\hline%
						yeastME3&0.81&0.82&0.49&0.0&0.81&0.45&0.17&0.77\\%
						\hline%
					\end{tabular}}%
					\caption{G-mean}
					\label{tab3}
				\end{center}
			\end{table}
			
			\begin{table}[h]
				\begin{center}
					\resizebox{\textwidth}{!}{%
					\begin{tabular}{|c|c|c|c|c|c|c|c|c|}%
						\hline%
						&Drzewo&kNN&NKB&SVM&RForest&BAGGING&BOOSTING&STACKING\\%
						\hline%
						abalone0\_4&0.48&0.62&0.45&0.0&0.58&0.45&0.29&0.53\\%
						\hline%
						abalone0\_4\_16\_29&0.34&0.34&0.27&0.0&0.34&0.27&0.14&0.25\\%
						\hline%
						abalone16\_29&0.27&0.22&0.2&0.0&0.2&0.2&0.14&0.14\\%
						\hline%
						balance\_scale&0.08&0.0&0.0&0.0&0.0&0.0&0.0&0.0\\%
						\hline%
						breast\_cancer&0.39&0.25&0.49&0.11&0.44&0.48&0.36&0.32\\%
						\hline%
						bupa&0.58&0.51&0.58&0.0&0.6&0.59&0.45&0.51\\%
						\hline%
						car&0.86&0.61&0.39&0.76&0.72&0.4&0.79&0.85\\%
						\hline%
						cmc&0.34&0.35&0.46&0.23&0.34&0.46&0.3&0.23\\%
						\hline%
						ecoli&0.54&0.49&0.46&0.0&0.57&0.47&0.64&0.46\\%
						\hline%
						german&0.49&0.38&0.58&0.22&0.52&0.58&0.02&0.29\\%
						\hline%
						glass&0.37&0.16&0.18&0.0&0.11&0.18&0.11&0.0\\%
						\hline%
						haberman&0.29&0.39&0.31&0.02&0.28&0.35&0.22&0.27\\%
						\hline%
						heart\_cleveland&0.21&0.0&0.39&0.0&0.0&0.37&0.24&0.0\\%
						\hline%
						hepatitis&0.5&0.1&0.56&0.0&0.55&0.53&0.34&0.41\\%
						\hline%
						horse\_colic&0.71&0.6&0.73&0.37&0.8&0.73&0.51&0.72\\%
						\hline%
						ionosphere&0.81&0.7&0.82&0.91&0.91&0.83&0.7&0.88\\%
						\hline%
						new\_thyroid&0.89&0.87&0.9&0.0&0.92&0.9&0.87&0.89\\%
						\hline%
						postoperative&0.22&0.0&0.19&0.0&0.0&0.17&0.35&0.0\\%
						\hline%
						seeds&0.85&0.9&0.89&0.92&0.88&0.89&0.85&0.9\\%
						\hline%
						solar\_flare&0.15&0.0&0.19&0.0&0.09&0.18&0.09&0.0\\%
						\hline%
						transfusion&0.23&0.28&0.24&0.08&0.28&0.25&0.31&0.15\\%
						\hline%
						vehicle&0.87&0.86&0.54&0.02&0.94&0.54&0.58&0.84\\%
						\hline%
						vertebal&0.67&0.73&0.72&0.0&0.73&0.71&0.57&0.7\\%
						\hline%
						yeastME1&0.62&0.7&0.15&0.0&0.7&0.16&0.28&0.66\\%
						\hline%
						yeastME2&0.29&0.21&0.07&0.0&0.22&0.07&0.07&0.0\\%
						\hline%
						yeastME3&0.67&0.73&0.24&0.0&0.73&0.23&0.06&0.69\\%
						\hline%
					\end{tabular}}%
						\caption{F1}
						\label{tab4}
					\end{center}
				\end{table}
