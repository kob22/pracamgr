\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}
\bibitem{baggingc}{L. Breiman. Bagging Predictors, Machine Learning, 1996.}
\bibitem{boostingc}{Y. Freund,  R. E. Schapire. Experiments with a~New Boosting Algorithm. Proceedings of the 13th International Conference on Machine Learning, Bari, 1996.}
\bibitem{adaboostc}{Y. Freund,  R. E. Schapire. A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting, 1996.}
\bibitem{randomFc}{L. Breiman. Random Forests. Machine Learning, 2001.}
\bibitem{KubatMatwin}{M. Kubat i~S. Matwin. Addresing the curse of imbalanced training sets: one-side selection.}
\bibitem{stackingc}{D. Wolpert. Stacked Generalization., Neural Networks, 1992.}
\bibitem{tomelinksc}{I. Tomek. Two modifications of CNN. IEEE Transactions on Systems Man and Communications, 1976.}
\bibitem{enn}{D. L. Wilson. Asymptotic properties of nearest neighbor rules using edited data. IEEE	Transactions on Systems, Man, and Communications, 1972.}
\bibitem{ncr}{J. Laurikkala. Improving identification of difficult small classes by balancing class distribution. Technical report, University of Tampere, 2001.}
\bibitem{smotec}{N. V. Chawla, K. W. Bowyer, L. O. Hall, i~W. P. Kegelmeyer. SMOTE: synthetic minority over-sampling technique, 2002.}
\bibitem{adasync}{H. He, Y. Bai, E. A. Garcia, i~S. Li. ADASYN: Adaptive synthetic sampling approach	for imbalanced learning, 2008.}
\bibitem{hybrid}{G. Batista, R. C. Prati, i~M. C. Monard. A study of the behavior of several methods for	balancing machine learning training data. ACM SIGKDD Explorations Newsletter, 2004.}
\bibitem{Garcia}{H.	He i~E.	A. Garcia. Learning from imbalanced data. IEEE Transactions on Data and Knowledge Engineering, 2009.}
\bibitem{gocardless}{N. Hockham: Machine learning with imbalanced data sets https://www.youtube.com/watch?v=X9MZtvvQDR4}
\bibitem{Bishop}{C. M. Bishop. Neural Networks for Pattern Recognition. Claredon press. Oxford, 1995.}
\bibitem{boosting}{Long P, Servedio R. Random Classification Noise Defeats All Convex Potential Boosters}
\bibitem{uci}{The UCI Machine Learning Repository, https://archive.ics.uci.edu/ml/}
\bibitem{hyper}{F. Hu, X. Liu, J. Dai i~H. Yu. A Novel Algorithm for Imbalance Data Classification Based on Neighborhood Hypergraph}
\bibitem{StefImbalanced}{J. Stefanowski. Dealing with Data Difficulty Factors while Learning from Imbalanced Data.}
\bibitem{przykladyklas}{K.Napierala, J.Stefanowski. Identification of Different Types of Minority Class Examples in Imbalanced Data. In: E. Corchado, V. Snasel, A.Abraham, M. Wozniak et al. (eds): Hybrid Artificial Intelligence Systems, Proc. 7th Int Conference HAIS 2012.}
\bibitem{python}{Python Software Foundation. https://www.python.org/}
\bibitem{scikit}{scikit-learn Machine Learning in Python. http://scikit-learn.org/}
\bibitem{imlearn}{imbalanced-learn. http://contrib.scikit-learn.org/imbalanced-learn/}
\bibitem{mlxtend}{S. Raschka. Mlxtend (machine learning extensions), https://github.com/rasbt/mlxtend}

\end{thebibliography}
\listoffigures



\addcontentsline{toc}{section}{Spis rysunk√≥w}
\listoftables

\addcontentsline{toc}{section}{Spis tabel}