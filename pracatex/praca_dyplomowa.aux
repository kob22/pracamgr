\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\@writefile{toc}{\contentsline {chapter}{Wst\IeC {\k e}p}{1}{chapter*.2}}
\@writefile{toc}{\contentsline {chapter}{Zakres i cel pracy}{3}{chapter*.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Wst\IeC {\k e}p teoretyczny}{5}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Klasyfikacja danych}{5}{section.1.1}}
\@writefile{tdo}{\contentsline {todo}{usunac pojedyncze znaki na koncu zdania, wykonac skrypt}{5}{section*.4}}
\pgfsyspdfmark {pgfid1}{7681439}{34737446}
\@writefile{tdo}{\contentsline {todo}{poprawic znaki cytatu, nie dodaje spacji po}{5}{section*.5}}
\pgfsyspdfmark {pgfid6}{7681439}{34737446}
\pgfsyspdfmark {pgfid4}{37920833}{34754372}
\pgfsyspdfmark {pgfid5}{40689729}{34483556}
\pgfsyspdfmark {pgfid9}{37920833}{28675290}
\pgfsyspdfmark {pgfid10}{40689729}{28404474}
\@writefile{tdo}{\contentsline {todo}{napisac o tym, \IeC {\.z}e niekt\IeC {\'o}re zbiory s\IeC {\k a} multiklasowe, natomiast dane sprowadzone s\IeC {\k a} do 2 klas}{5}{section*.6}}
\pgfsyspdfmark {pgfid11}{7681439}{33607101}
\@writefile{tdo}{\contentsline {todo}{napisac o podejsci one vs all}{5}{section*.7}}
\pgfsyspdfmark {pgfid16}{7681439}{33607101}
\pgfsyspdfmark {pgfid14}{37920833}{23651478}
\pgfsyspdfmark {pgfid15}{40689729}{23380662}
\pgfsyspdfmark {pgfid19}{37920833}{15386782}
\pgfsyspdfmark {pgfid20}{40689729}{15115966}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Przyk\IeC {\l }ad danych treningowych sk\IeC {\l }adaj\IeC {\k a}cych si\IeC {\k e} z 5 atrybut\IeC {\'o}w oraz klasy decyzyjnej. W ostatniej kolumnie znajduje si\IeC {\k e} wynik klasyfikacji. W pi\IeC {\k e}ciu przypadkach, klasyfikator poprawnie wskaza\IeC {\l } klas\IeC {\k e}.\relax }}{6}{table.caption.8}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{system_informacyjny}{{1.1}{6}{Przykład danych treningowych składających się z 5 atrybutów oraz klasy decyzyjnej. W ostatniej kolumnie znajduje się wynik klasyfikacji. W pięciu przypadkach, klasyfikator poprawnie wskazał klasę.\relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Wybrane algorytmy klasyfikacji danych}{6}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Drzewo decyzyjne}{6}{subsection.1.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Drzewo decyzyjne z maksymaln\IeC {\k a} g\IeC {\l }\IeC {\k e}boko\IeC {\'s}ci\IeC {\k a} r\IeC {\'o}wn\IeC {\k a} 3. Drzewo zbudowane dla danych $iris-data$, zawiera trzy klasy (gatunki) setosa, versicolor i virginica oraz cztery atrybuty d\IeC {\l }ugo\IeC {\'s}\IeC {\'c} i szeroko\IeC {\'s}\IeC {\'c} kwiatu peta i sepal. Podzia\IeC {\l } zosta\IeC {\l } dokonany ze wsp\IeC {\'o}\IeC {\l }czynnikiem gini.\relax }}{7}{figure.caption.9}}
\newlabel{fig:drzewodec}{{1.1}{7}{Drzewo decyzyjne z maksymalną głębokością równą 3. Drzewo zbudowane dla danych $iris-data$, zawiera trzy klasy (gatunki) setosa, versicolor i virginica oraz cztery atrybuty długość i szerokość kwiatu peta i sepal. Podział został dokonany ze współczynnikiem gini.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Naiwny klasyfikator bayesowski}{8}{subsection.1.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Klasyfikator k najbli\IeC {\.z}szych s\IeC {\k a}siad\IeC {\'o}w (kNN)}{8}{subsection.1.2.3}}
\citation{Bishop}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Przyk\IeC {\l }ad klasyfikatora kNN. Klasyfikator ma przewidzie\IeC {\'c} klas\IeC {\k e} dla czerwonego punktu. Dla k=3 wyszukuje trzech najbli\IeC {\.z}szych s\IeC {\k a}siad\IeC {\'o}w, w tym przypadku nada\IeC {\l }by klas\IeC {\k e} fioletow\IeC {\k a}, natomiast dla k=6 wyszukuje sze\IeC {\'s}ciu najbli\IeC {\.z}szych s\IeC {\k a}siad\IeC {\'o}w i punktowi nada\IeC {\l }by klas\IeC {\k e} zielon\IeC {\k a}.\relax }}{9}{figure.caption.10}}
\newlabel{fig:klasknn}{{1.2}{9}{Przykład klasyfikatora kNN. Klasyfikator ma przewidzieć klasę dla czerwonego punktu. Dla k=3 wyszukuje trzech najbliższych sąsiadów, w tym przypadku nadałby klasę fioletową, natomiast dla k=6 wyszukuje sześciu najbliższych sąsiadów i punktowi nadałby klasę zieloną.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Las losowy}{9}{subsection.1.2.4}}
\@writefile{tdo}{\contentsline {todo}{Jest to jeden z element\IeC {\'o}w bagging, mo\IeC {\.z}e wspomnie\IeC {\'c}, albo da\IeC {\'c} w innym miejscu?}{9}{section*.11}}
\pgfsyspdfmark {pgfid21}{7681439}{28588827}
\pgfsyspdfmark {pgfid24}{37920833}{28605753}
\pgfsyspdfmark {pgfid25}{40689729}{28334937}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}Maszyna wektor\IeC {\'o}w no\IeC {\'s}nych}{10}{subsection.1.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Przyk\IeC {\l }ad klasyfikatora SVM z maksymalnym marginesem oddzielaj\IeC {\k a}cym dwie klasy\relax }}{10}{figure.caption.12}}
\newlabel{fig:klassvm}{{1.3}{10}{Przykład klasyfikatora SVM z maksymalnym marginesem oddzielającym dwie klasy\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.6}Zesp\IeC {\'o}\IeC {\l } klasyfikator\IeC {\'o}w}{11}{subsection.1.2.6}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Meta-metody}{11}{section.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Bagging}{11}{subsection.1.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Boosting}{12}{subsection.1.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Stacking}{13}{subsection.1.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Wst\IeC {\k e}pne przetwarzanie danych}{13}{section.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Brakuj\IeC {\k a}ce warto\IeC {\'s}ci atrybut\IeC {\'o}w}{13}{subsection.1.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{Usuni\IeC {\k e}cie niekompletnych obserwacji}{14}{section*.13}}
\@writefile{toc}{\contentsline {subsubsection}{Imputacja danych}{14}{section*.14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Transformacja danych}{14}{subsection.1.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{Skalowanie}{14}{section*.15}}
\@writefile{toc}{\contentsline {subsubsection}{Standaryzacja}{15}{section*.16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Dane kategoryczne}{15}{subsection.1.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{Mapowanie danych kategorycznych}{15}{section*.17}}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces Przyk\IeC {\l }ad z kategorycznymi danymi.\relax }}{16}{table.caption.18}}
\newlabel{danekategoryczne}{{1.2}{16}{Przykład z kategorycznymi danymi.\relax }{table.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{Dane nominalne}{16}{section*.19}}
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces Przyk\IeC {\l }ad z kategorycznymi danymi po odpowiednim kodowaniu.\relax }}{16}{table.caption.20}}
\newlabel{danekategoryczne2}{{1.3}{16}{Przykład z kategorycznymi danymi po odpowiednim kodowaniu.\relax }{table.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Redukcja ilo\IeC {\'s}ci atrybut\IeC {\'o}w}{17}{subsection.1.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{Sekwencyjna selekcja post\IeC {\k e}puj\IeC {\k a}ca oraz sekwencyjna selekcja wsteczna}{17}{section*.21}}
\@writefile{toc}{\contentsline {subsubsection}{Analiza g\IeC {\l }\IeC {\'o}wnych sk\IeC {\l }adowych}{17}{section*.22}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Ocena poprawno\IeC {\'s}ci klasyfikacji}{18}{section.1.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Miary jako\IeC {\'s}ci klasyfikacji danych}{18}{subsection.1.5.1}}
\newlabel{miary}{{1.5.1}{18}{Miary jakości klasyfikacji danych}{subsection.1.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.4}{\ignorespaces Macierz pomy\IeC {\l }ek\relax }}{18}{table.caption.23}}
\newlabel{macierz_pomylek}{{1.4}{18}{Macierz pomyłek\relax }{table.caption.23}{}}
\citation{KubatMatwin}
\newlabel{error_rate}{{1.5.1}{19}{Miary jakości klasyfikacji danych}{table.caption.23}{}}
\citation{Garcia}
\@writefile{toc}{\contentsline {subsubsection}{Krzywa ROC}{20}{section*.24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}Nadmierne dopasowanie i wariancja klasyfikatora}{20}{subsection.1.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Przyk\IeC {\l }ad krzywej ROC, dla naiwnego klasyfikatora bayesowskiego oraz dla regresji logistycznej dla danych $abalone041629$.\relax }}{21}{figure.caption.25}}
\newlabel{fig:krzywa_roc}{{1.4}{21}{Przykład krzywej ROC, dla naiwnego klasyfikatora bayesowskiego oraz dla regresji logistycznej dla danych $abalone041629$.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Obci\IeC {\k a}\IeC {\.z}enie i wariancja na przyk\IeC {\l }adzie tarczy strzeleckiej. Klasyfikator poprawnie przewiduje klasy je\IeC {\'s}li niebieskie kropki trafiaj\IeC {\k a} w \IeC {\'s}rodek tarczy.\relax }}{22}{figure.caption.26}}
\newlabel{fig:biasvariance}{{1.5}{22}{Obciążenie i wariancja na przykładzie tarczy strzeleckiej. Klasyfikator poprawnie przewiduje klasy jeśli niebieskie kropki trafiają w środek tarczy.\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.3}Metody pomiaru jako\IeC {\'s}ci klasyfikacji danych}{22}{subsection.1.5.3}}
\newlabel{testowanieklasyfikatora}{{1.5.3}{22}{Metody pomiaru jakości klasyfikacji danych}{subsection.1.5.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Metoda z jednym zbiorem}{23}{section*.27}}
\@writefile{toc}{\contentsline {subsubsection}{Metoda z wydzielonym zbiorem testowym (ang. \textit  {the holdout method})}{23}{section*.28}}
\@writefile{toc}{\contentsline {subsubsection}{Sprawdzian krzy\IeC {\.z}owy z p przyk\IeC {\l }adami (ang. \textit  {leave-p-out cross-validation})}{23}{section*.29}}
\@writefile{toc}{\contentsline {subsubsection}{Sprawdzian krzy\IeC {\.z}owy minus jeden element (ang. \textit  {leave-one-out cross-validation})}{24}{section*.30}}
\@writefile{toc}{\contentsline {subsubsection}{Sprawdzian krzy\IeC {\.z}owy k-krotny (ang. \textit  {k-fold cross-validation})}{24}{section*.31}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Przyk\IeC {\l }ad sprawdzianu krzy\IeC {\.z}owego k-krotnego, k=4.\relax }}{24}{figure.caption.32}}
\newlabel{fig:sprawdziankrzyzowy}{{1.6}{24}{Przykład sprawdzianu krzyżowego k-krotnego, k=4.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{R\IeC {\'o}wnomierny sprawdzian krzy\IeC {\.z}owy k-krotny (ang. \textit  {Stratified k-fold cross-validation})}{24}{section*.33}}
\citation{gocardless}
\citation{przykladyklas}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Klasyfikacja danych niezr\IeC {\'o}wnowa\IeC {\.z}onych}{25}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Dane niezr\IeC {\'o}wnowa\IeC {\.z}one}{25}{section.2.1}}
\@writefile{tdo}{\contentsline {todo}{dodac przyklady danych mniejszosciowych}{25}{section*.34}}
\pgfsyspdfmark {pgfid26}{6526379}{11472431}
\pgfsyspdfmark {pgfid29}{37920833}{11489357}
\pgfsyspdfmark {pgfid30}{40689729}{11218541}
\@writefile{tdo}{\contentsline {todo}{dodac obrazek danyych safe border itd.}{26}{section*.35}}
\pgfsyspdfmark {pgfid31}{4661699}{35699288}
\@writefile{tdo}{\contentsline {todo}{podac wykresy przyk\IeC {\l }ady danych niezr\IeC {\'o}wnowa\IeC {\.z}onych}{26}{section*.36}}
\pgfsyspdfmark {pgfid36}{4661699}{35699288}
\pgfsyspdfmark {pgfid32}{1204675}{35716214}
\pgfsyspdfmark {pgfid33}{3973571}{35445398}
\pgfsyspdfmark {pgfid37}{1204675}{31955814}
\pgfsyspdfmark {pgfid38}{3973571}{31684998}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}R\IeC {\'o}wnowa\IeC {\.z}enie rozk\IeC {\l }adu klas w zbiorze danych}{26}{section.2.2}}
\newlabel{rozdzialopissamplingu}{{2.2}{26}{Równoważenie rozkładu klas w zbiorze danych}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Metody undersampling}{26}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Metody oversampling}{27}{subsection.2.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Metody hybrydowe}{27}{subsection.2.2.3}}
\citation{python}
\citation{scikit}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Przeprowadzone badania}{29}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Opis platformy i spos\IeC {\'o}b realizacji bada\IeC {\'n}}{29}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}J\IeC {\k e}zyk python}{29}{subsection.3.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Biblioteka scikit-learn}{29}{subsection.3.1.2}}
\citation{imlearn}
\citation{mlxtend}
\citation{uci}
\citation{hyper}
\citation{StefImbalanced}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Biblioteka imbalanced-learn}{30}{subsection.3.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Pozosta\IeC {\l }e u\IeC {\.z}yte biblioteki}{30}{subsection.3.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{Mlxtend}{30}{section*.37}}
\@writefile{toc}{\contentsline {subsubsection}{Numpy}{30}{section*.38}}
\@writefile{toc}{\contentsline {subsubsection}{Maptolib}{30}{section*.39}}
\@writefile{toc}{\contentsline {subsubsection}{Texttable}{30}{section*.40}}
\@writefile{toc}{\contentsline {subsubsection}{Pylatex}{30}{section*.41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}opisac co zaimplementowane?}{30}{subsection.3.1.5}}
\@writefile{tdo}{\contentsline {todo}{ze wlasna krosswalidacja, ze wlasne miary, klasyfikator. itd}{30}{section*.42}}
\pgfsyspdfmark {pgfid41}{5816759}{10805334}
\pgfsyspdfmark {pgfid42}{1204675}{10822260}
\pgfsyspdfmark {pgfid43}{3973571}{10551444}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Opis danych u\IeC {\.z}ytych w badaniach}{30}{section.3.2}}
\citation{przykladyklas}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Dane u\IeC {\.z}yte w badaniach wraz z charakterystyk\IeC {\k a}.\relax }}{32}{table.caption.43}}
\newlabel{danebadania}{{3.1}{32}{Dane użyte w badaniach wraz z charakterystyką.\relax }{table.caption.43}{}}
\@writefile{toc}{\contentsline {subsubsection}{Analiza klas mniejszo\IeC {\'s}ciowych}{32}{section*.44}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Analiza przynale\IeC {\.z}no\IeC {\'s}ci przyk\IeC {\l }ad\IeC {\'o}w z klasy mniejszo\IeC {\'s}ciowej do grup. Dane posortowano w kolejno\IeC {\'s}ci od naj\IeC {\l }atwiejszych w klasyfikacji do najtrudniejszych.\relax }}{33}{table.caption.45}}
\newlabel{dane_analiza_grupy}{{3.2}{33}{Analiza przynależności przykładów z klasy mniejszościowej do grup. Dane posortowano w kolejności od najłatwiejszych w klasyfikacji do najtrudniejszych.\relax }{table.caption.45}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Ocena klasyfikatora w sprawdzianie krzy\IeC {\.z}owym k-krotnym.}{34}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Test sposob\IeC {\'o}w oceny klasyfikatora}{34}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} oraz b\IeC {\l }\IeC {\k a}d klasyfikatora}{35}{section*.46}}
\@writefile{toc}{\contentsline {subsubsection}{Czu\IeC {\l }o\IeC {\'s}\IeC {\'c}, specyficzno\IeC {\'s}\IeC {\'c}, FPR oraz precyzja}{35}{section*.47}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Wykresy czu\IeC {\l }o\IeC {\'s}ci, specyficzno\IeC {\'s}ci oraz precyzji w zale\IeC {\.z}no\IeC {\'s}ci od wielko\IeC {\'s}ci klasy mniejszo\IeC {\'s}ciowej dla r\IeC {\'o}wnomiernego oraz losowego sprawdzianu krzy\IeC {\.z}owego (k=10).\relax }}{37}{figure.caption.48}}
\newlabel{fig:wskazniki}{{3.1}{37}{Wykresy czułości, specyficzności oraz precyzji w zależności od wielkości klasy mniejszościowej dla równomiernego oraz losowego sprawdzianu krzyżowego (k=10).\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Odchylenie standardowe miar czu\IeC {\l }o\IeC {\'s}ci, specyficzno\IeC {\'s}ci oraz precyzji w zale\IeC {\.z}no\IeC {\'s}ci od wielko\IeC {\'s}ci klasy mniejszo\IeC {\'s}ciowej dla r\IeC {\'o}wnomiernego oraz losowego sprawdzianu krzy\IeC {\.z}owego (k=10).\relax }}{38}{figure.caption.49}}
\newlabel{fig:wskaznikistd}{{3.2}{38}{Odchylenie standardowe miar czułości, specyficzności oraz precyzji w zależności od wielkości klasy mniejszościowej dla równomiernego oraz losowego sprawdzianu krzyżowego (k=10).\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsubsection}{Miara $F_1$}{38}{section*.50}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Wykres odchylenia standardowego miar F1 oraz \IeC {\'s}redniej miar F1, w zale\IeC {\.z}no\IeC {\'s}ci od wielko\IeC {\'s}ci klasy mniejszo\IeC {\'s}ciowej dla r\IeC {\'o}wnomiernego oraz losowego sprawdzianu krzy\IeC {\.z}owego (k=10).\relax }}{40}{figure.caption.51}}
\newlabel{fig:wykresf1}{{3.3}{40}{Wykres odchylenia standardowego miar F1 oraz średniej miar F1, w zależności od wielkości klasy mniejszościowej dla równomiernego oraz losowego sprawdzianu krzyżowego (k=10).\relax }{figure.caption.51}{}}
\@writefile{toc}{\contentsline {subsubsection}{Miara G-mean}{40}{section*.52}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Wykres odchylenia standardowego miar G-mean oraz \IeC {\'s}redniej miar G-mean w zale\IeC {\.z}no\IeC {\'s}ci, od wielko\IeC {\'s}ci klasy mniejszo\IeC {\'s}ciowej, dla r\IeC {\'o}wnomiernego oraz losowego sprawdzianu krzy\IeC {\.z}owego (k=10).\relax }}{41}{figure.caption.53}}
\newlabel{fig:wykresgmean}{{3.4}{41}{Wykres odchylenia standardowego miar G-mean oraz średniej miar G-mean w zależności, od wielkości klasy mniejszościowej, dla równomiernego oraz losowego sprawdzianu krzyżowego (k=10).\relax }{figure.caption.53}{}}
\@writefile{toc}{\contentsline {subsubsection}{Krzywa ROC i miara AUC}{41}{section*.54}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Wykresy krzywych ROC dla klasyfikator\IeC {\'o}w ze sprawdzianu krzy\IeC {\.z}owego r\IeC {\'o}wnomiernego i normalnego wraz z obliczon\IeC {\k a} \IeC {\'s}redni\IeC {\k a} $ROC_{AVG}$ oraz $ROC_{merge}$.\relax }}{43}{figure.caption.55}}
\newlabel{fig:cv_roc}{{3.5}{43}{Wykresy krzywych ROC dla klasyfikatorów ze sprawdzianu krzyżowego równomiernego i normalnego wraz z obliczoną średnią $ROC_{AVG}$ oraz $ROC_{merge}$.\relax }{figure.caption.55}{}}
\@writefile{toc}{\contentsline {subsubsection}{Podsumowanie}{43}{section*.56}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Przyk\IeC {\l }ad obliczonych miar dla r\IeC {\'o}wnomiernego sprawdzianu krzy\IeC {\.z}owego. Dla k=2, gdzie nie by\IeC {\l }o pozytywnie sklasyfikowanych przyk\IeC {\l }ad\IeC {\'o}w, warto\IeC {\'s}ci sensitivity, precision, $F_1$ zosta\IeC {\l }y ustawione na 0, aby unikn\IeC {\k a}\IeC {\'c} dzielenia przez zero. W wierszu oznaczonym jako "tp,fp,tn", wska\IeC {\'z}niki zosta\IeC {\l }y obliczone na podstawie wsp\IeC {\'o}lnej macierzy pomy\IeC {\l }ek.\relax }}{44}{table.caption.57}}
\newlabel{przykladoblwsp}{{3.3}{44}{Przykład obliczonych miar dla równomiernego sprawdzianu krzyżowego. Dla k=2, gdzie nie było pozytywnie sklasyfikowanych przykładów, wartości sensitivity, precision, $F_1$ zostały ustawione na 0, aby uniknąć dzielenia przez zero. W wierszu oznaczonym jako "tp,fp,tn", wskaźniki zostały obliczone na podstawie wspólnej macierzy pomyłek.\relax }{table.caption.57}{}}
\@writefile{tdo}{\contentsline {todo}{dac odnosnik do rozdzialu}{44}{section*.58}}
\pgfsyspdfmark {pgfid46}{5816759}{29677512}
\pgfsyspdfmark {pgfid47}{1204675}{29694438}
\pgfsyspdfmark {pgfid48}{3973571}{29423622}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}R\IeC {\'o}wnowa\IeC {\.z}enie liczebno\IeC {\'s}ci klas w danych w klasyfikacji ze sprawdzianem krzy\IeC {\.z}owym}{44}{section.3.4}}
\newlabel{rozdzialbalansowanie}{{3.4}{44}{Równoważenie liczebności klas w danych w klasyfikacji ze sprawdzianem krzyżowym}{section.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Przyk\IeC {\l }ad sprawdzianu krzy\IeC {\.z}owego z wykonanym oversamplingiem przed sprawdzianem. Sztucznie wygenerowane dane (niebiesko-fioletowy prostok\IeC {\k a}t) zosta\IeC {\l }y u\IeC {\.z}yte jako zbi\IeC {\'o}r testowy.\relax }}{45}{figure.caption.59}}
\newlabel{fig:oversampling_wrong}{{3.6}{45}{Przykład sprawdzianu krzyżowego z wykonanym oversamplingiem przed sprawdzianem. Sztucznie wygenerowane dane (niebiesko-fioletowy prostokąt) zostały użyte jako zbiór testowy.\relax }{figure.caption.59}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Wyniki sprawdzianu krzy\IeC {\.z}owego (metoda pierwsza) drzewa decyzyjnego z oversampling SMOTE. Dane w kolumnach "Decision Tree TEST" to wyniki otrzymane na podstawie zbioru walidacyjnego. Ostatnia kolumna zawiera r\IeC {\'o}\IeC {\.z}nic\IeC {\k e} miar G ze sprawdzianu krzy\IeC {\.z}owego i zbioru walidacyjnego $G-G_T$ (im bli\IeC {\.z}ej zera tym lepiej).\relax }}{47}{table.caption.60}}
\newlabel{CVoversampling1}{{3.4}{47}{Wyniki sprawdzianu krzyżowego (metoda pierwsza) drzewa decyzyjnego z oversampling SMOTE. Dane w kolumnach "Decision Tree TEST" to wyniki otrzymane na podstawie zbioru walidacyjnego. Ostatnia kolumna zawiera różnicę miar G ze sprawdzianu krzyżowego i zbioru walidacyjnego $G-G_T$ (im bliżej zera tym lepiej).\relax }{table.caption.60}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Wyniki sprawdzianu krzy\IeC {\.z}owego (metoda druga) drzewa decyzyjnego z oversampling SMOTE. Dane w kolumnach "Decision Tree TEST" to wyniki otrzymane na podstawie zbioru walidacyjnego. Ostatnia kolumna zawiera r\IeC {\'o}\IeC {\.z}nic\IeC {\k e} miar G ze sprawdzianu krzy\IeC {\.z}owego i zbioru walidacyjnego $G-G_T$ (im bli\IeC {\.z}ej zera tym lepiej).\relax }}{48}{table.caption.61}}
\newlabel{CVoversampling2}{{3.5}{48}{Wyniki sprawdzianu krzyżowego (metoda druga) drzewa decyzyjnego z oversampling SMOTE. Dane w kolumnach "Decision Tree TEST" to wyniki otrzymane na podstawie zbioru walidacyjnego. Ostatnia kolumna zawiera różnicę miar G ze sprawdzianu krzyżowego i zbioru walidacyjnego $G-G_T$ (im bliżej zera tym lepiej).\relax }{table.caption.61}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Meta-metody}{49}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Bagging}{49}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Bagging z naiwnym klasyfikatorem bayesowskim}{49}{subsection.4.1.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} klasyfikatora bagging, dla $max\_features = 1.0$ oraz $max\_samples = 1.0$\relax }}{50}{table.caption.62}}
\newlabel{bagging_11}{{4.1}{50}{Dokładność klasyfikatora bagging, dla $max\_features = 1.0$ oraz $max\_samples = 1.0$\relax }{table.caption.62}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej, dla klasyfikatora bagging i parametr\IeC {\'o}w: $max\_features = 1.0$ oraz $max\_samples = 1.0$.\relax }}{51}{table.caption.63}}
\newlabel{bagging-specyficznosc11}{{4.2}{51}{Specyficzność klasy mniejszościowej, dla klasyfikatora bagging i parametrów: $max\_features = 1.0$ oraz $max\_samples = 1.0$.\relax }{table.caption.63}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} klasyfikatora bagging, dla $max\_features = 0.72$ oraz $max\_samples = 0.68$\relax }}{52}{table.caption.64}}
\newlabel{bagging_acc2}{{4.3}{52}{Dokładność klasyfikatora bagging, dla $max\_features = 0.72$ oraz $max\_samples = 0.68$\relax }{table.caption.64}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej, dla klasyfikatora bagging i parametr\IeC {\'o}w: $max\_features = 0.72$ oraz $max\_samples = 0.68$.\relax }}{52}{table.caption.65}}
\newlabel{baggin_spec2}{{4.4}{52}{Specyficzność klasy mniejszościowej, dla klasyfikatora bagging i parametrów: $max\_features = 0.72$ oraz $max\_samples = 0.68$.\relax }{table.caption.65}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Bagging drzewa decyzyjne}{53}{subsection.4.1.2}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} klasyfikatora bagging drzewo decyzyjne dla parametr\IeC {\'o}w: $max\_features = 1$ oraz $max\_samples = 1$.\relax }}{54}{table.caption.66}}
\newlabel{baggingdrzewoacc}{{4.5}{54}{Dokładność klasyfikatora bagging drzewo decyzyjne dla parametrów: $max\_features = 1$ oraz $max\_samples = 1$.\relax }{table.caption.66}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej, dla klasyfikatora bagging z drzewem decyzyjnym, z ustawionymi parametrami: $max\_features = 1$ oraz $max\_samples = 1$.\relax }}{55}{table.caption.67}}
\newlabel{baggingdrzewospec}{{4.6}{55}{Specyficzność klasy mniejszościowej, dla klasyfikatora bagging z drzewem decyzyjnym, z ustawionymi parametrami: $max\_features = 1$ oraz $max\_samples = 1$.\relax }{table.caption.67}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} klasyfikatora bagging, dla $max\_features = 0.9$ oraz $max\_samples = 0.8$\relax }}{56}{table.caption.68}}
\newlabel{baggingdrzewoacc2}{{4.7}{56}{Dokładność klasyfikatora bagging, dla $max\_features = 0.9$ oraz $max\_samples = 0.8$\relax }{table.caption.68}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Miara F-1 klasy mniejszo\IeC {\'s}ciowej. Klasyfikator bagging drzewo decyzyjne z parametrami $max\_features = 0.9$ oraz $max\_samples = 0.8$.\relax }}{57}{table.caption.69}}
\newlabel{baggingdrzewo2f1}{{4.8}{57}{Miara F-1 klasy mniejszościowej. Klasyfikator bagging drzewo decyzyjne z parametrami $max\_features = 0.9$ oraz $max\_samples = 0.8$.\relax }{table.caption.69}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} klasyfikatora bagging drzewo decyzyjne, dla $max\_features = 0.9$ oraz $max\_samples = 0.8$\relax }}{58}{table.caption.70}}
\newlabel{baggingdrzewo2acc2}{{4.9}{58}{Dokładność klasyfikatora bagging drzewo decyzyjne, dla $max\_features = 0.9$ oraz $max\_samples = 0.8$\relax }{table.caption.70}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej dla klasyfikatora bagging z drzewem decyzyjnym z ustawieniami $max\_features = 0.9$ oraz $max\_samples = 0.8$.\relax }}{59}{table.caption.71}}
\newlabel{baggingdrzewo2spec2}{{4.10}{59}{Specyficzność klasy mniejszościowej dla klasyfikatora bagging z drzewem decyzyjnym z ustawieniami $max\_features = 0.9$ oraz $max\_samples = 0.8$.\relax }{table.caption.71}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Bagging z klasyfikatorem kNN}{59}{subsection.4.1.3}}
\@writefile{lot}{\contentsline {table}{\numberline {4.11}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} klasyfikatora bagging z kNN, dla $max\_features = 1.0$ oraz $max\_samples = 1.0$\relax }}{61}{table.caption.72}}
\newlabel{baggingknnacc}{{4.11}{61}{Dokładność klasyfikatora bagging z kNN, dla $max\_features = 1.0$ oraz $max\_samples = 1.0$\relax }{table.caption.72}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.12}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej dla klasyfikatora bagging z kNN i ustawieniami $max\_features = 1.0$ oraz $max\_samples = 1.0$.\relax }}{62}{table.caption.73}}
\newlabel{baggingknnspec}{{4.12}{62}{Specyficzność klasy mniejszościowej dla klasyfikatora bagging z kNN i ustawieniami $max\_features = 1.0$ oraz $max\_samples = 1.0$.\relax }{table.caption.73}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Boosting}{63}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}AdaBoost z naiwnym klasyfikatorem Bayesa}{63}{subsection.4.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.13}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} klasyfikatora AdaBoost z naiwnym klasyfikatorem Bayesa.\relax }}{64}{table.caption.74}}
\newlabel{adaboostNBacc2}{{4.13}{64}{Dokładność klasyfikatora AdaBoost z naiwnym klasyfikatorem Bayesa.\relax }{table.caption.74}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.14}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasyfikatora AdaBoost z NKB.\relax }}{64}{table.caption.75}}
\newlabel{adaboostNKBspec}{{4.14}{64}{Specyficzność klasyfikatora AdaBoost z NKB.\relax }{table.caption.75}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.15}{\ignorespaces Miara G-mean dla AdaBoost z NKB\relax }}{65}{table.caption.76}}
\newlabel{adaboostNKBgmean}{{4.15}{65}{Miara G-mean dla AdaBoost z NKB\relax }{table.caption.76}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}AdaBoost z drzewem decyzyjnym}{65}{subsection.4.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {4.16}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} klasyfikatora AdaBoost z drzewem decyzyjnym.\relax }}{66}{table.caption.77}}
\newlabel{adaboostdrzewo}{{4.16}{66}{Dokładność klasyfikatora AdaBoost z drzewem decyzyjnym.\relax }{table.caption.77}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.17}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasyfikatora AdaBoost z drzewem decyzyjnym.\relax }}{67}{table.caption.78}}
\newlabel{adaspecyficznosc}{{4.17}{67}{Specyficzność klasyfikatora AdaBoost z drzewem decyzyjnym.\relax }{table.caption.78}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Stacking}{68}{subsection.4.2.3}}
\@writefile{tdo}{\contentsline {todo}{dobrym pomyslem moze byc ze robi stabline wyniki, mozna go uzyc do roznych baz jako uniwersalny, albo zastosowac inne klasyfikatory zeby uzyskac lepszy wynik}{68}{section*.79}}
\pgfsyspdfmark {pgfid51}{5816759}{4915589}
\pgfsyspdfmark {pgfid52}{1204675}{4932515}
\pgfsyspdfmark {pgfid53}{3973571}{4661699}
\@writefile{lot}{\contentsline {table}{\numberline {4.18}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} klasyfikatora stacking.\relax }}{69}{table.caption.80}}
\newlabel{stackingdokladnosc}{{4.18}{69}{Dokładność klasyfikatora stacking.\relax }{table.caption.80}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.19}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej klasyfikatora stacking.\relax }}{69}{table.caption.81}}
\newlabel{stackingspec}{{4.19}{69}{Specyficzność klasy mniejszościowej klasyfikatora stacking.\relax }{table.caption.81}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.20}{\ignorespaces G-mean klasyfikatora stacking.\relax }}{70}{table.caption.82}}
\newlabel{stackinggmean}{{4.20}{70}{G-mean klasyfikatora stacking.\relax }{table.caption.82}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Por\IeC {\'o}wnanie meta-metod}{70}{subsection.4.2.4}}
\@writefile{lot}{\contentsline {table}{\numberline {4.21}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} meta-klasyfikator\IeC {\'o}w.\relax }}{71}{table.caption.83}}
\newlabel{accmeta}{{4.21}{71}{Dokładność meta-klasyfikatorów.\relax }{table.caption.83}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.22}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej dla meta-klasyfikator\IeC {\'o}w.\relax }}{72}{table.caption.84}}
\newlabel{specmeta}{{4.22}{72}{Specyficzność klasy mniejszościowej dla meta-klasyfikatorów.\relax }{table.caption.84}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.23}{\ignorespaces G-mean meta-klasyfikator\IeC {\'o}w.\relax }}{73}{table.caption.85}}
\newlabel{gmeanmeta}{{4.23}{73}{G-mean meta-klasyfikatorów.\relax }{table.caption.85}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.24}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} meta-klasyfikator\IeC {\'o}w dla testu nr 2.\relax }}{74}{table.caption.86}}
\newlabel{accmeta2}{{4.24}{74}{Dokładność meta-klasyfikatorów dla testu nr 2.\relax }{table.caption.86}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.25}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej dla meta-klasyfikator\IeC {\'o}w w te\IeC {\'s}cie nr 2.\relax }}{75}{table.caption.87}}
\newlabel{specmeta2}{{4.25}{75}{Specyficzność klasy mniejszościowej dla meta-klasyfikatorów w teście nr 2.\relax }{table.caption.87}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.26}{\ignorespaces G-mean meta-klasyfikator\IeC {\'o}w z badania nr 2.\relax }}{76}{table.caption.88}}
\newlabel{gmeanmeta2}{{4.26}{76}{G-mean meta-klasyfikatorów z badania nr 2.\relax }{table.caption.88}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Poprawa klasyfikacji danych mniejszo\IeC {\'s}ciowych}{76}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Oversampling metod\IeC {\k a} SMOTE}{77}{subsection.4.3.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.27}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej z u\IeC {\.z}yciem metody SMOTE.\relax }}{77}{table.caption.89}}
\newlabel{specsmote}{{4.27}{77}{Specyficzność klasy mniejszościowej z użyciem metody SMOTE.\relax }{table.caption.89}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.28}{\ignorespaces Miara G-mean z u\IeC {\.z}yciem metody SMOTE..\relax }}{78}{table.caption.90}}
\newlabel{gmeansmote}{{4.28}{78}{Miara G-mean z użyciem metody SMOTE..\relax }{table.caption.90}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Oversampling metod\IeC {\k a} ADASYN}{78}{subsection.4.3.2}}
\@writefile{lot}{\contentsline {table}{\numberline {4.29}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej z metod\IeC {\k a} ADASYN.\relax }}{79}{table.caption.91}}
\newlabel{specadasyn}{{4.29}{79}{Specyficzność klasy mniejszościowej z metodą ADASYN.\relax }{table.caption.91}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.30}{\ignorespaces Miara G-mean z u\IeC {\.z}yciem metody ADASYN.\relax }}{79}{table.caption.92}}
\newlabel{gmeanadasyn}{{4.30}{79}{Miara G-mean z użyciem metody ADASYN.\relax }{table.caption.92}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Undersampling NCR}{80}{subsection.4.3.3}}
\@writefile{lot}{\contentsline {table}{\numberline {4.31}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej z metod\IeC {\k a} NCR.\relax }}{80}{table.caption.93}}
\newlabel{specncr}{{4.31}{80}{Specyficzność klasy mniejszościowej z metodą NCR.\relax }{table.caption.93}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.32}{\ignorespaces Miara G-mean z metod\IeC {\k a}\IeC {\nobreakspace  }NCR.\relax }}{81}{table.caption.94}}
\newlabel{gmeanncr}{{4.32}{81}{Miara G-mean z metodą NCR.\relax }{table.caption.94}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Oversampling SMOTE i undersampling metod\IeC {\k a} ENN}{81}{subsection.4.3.4}}
\@writefile{lot}{\contentsline {table}{\numberline {4.33}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej z metod\IeC {\k a} SMOTEENN.\relax }}{82}{table.caption.95}}
\newlabel{specsmoteen}{{4.33}{82}{Specyficzność klasy mniejszościowej z metodą SMOTEENN.\relax }{table.caption.95}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.34}{\ignorespaces Miara G-mean z metod\IeC {\k a} SMOTEENN.\relax }}{82}{table.caption.96}}
\newlabel{gmeansmoteenn}{{4.34}{82}{Miara G-mean z metodą SMOTEENN.\relax }{table.caption.96}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Oversampling SMOTE i undersampling metod\IeC {\k a} Tomek links}{82}{subsection.4.3.5}}
\@writefile{tdo}{\contentsline {todo}{poprawic cos wcielo}{83}{section*.97}}
\pgfsyspdfmark {pgfid56}{8840235}{41444293}
\pgfsyspdfmark {pgfid59}{37920833}{41461219}
\pgfsyspdfmark {pgfid60}{40689729}{41190403}
\@writefile{lot}{\contentsline {table}{\numberline {4.35}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej dla metody SMOTE z Tomek links.\relax }}{83}{table.caption.98}}
\newlabel{specsmotetomek}{{4.35}{83}{Specyficzność klasy mniejszościowej dla metody SMOTE z Tomek links.\relax }{table.caption.98}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.36}{\ignorespaces Miara G-mean SMOTE z Tomek links.\relax }}{84}{table.caption.99}}
\newlabel{gmeansmotetomek}{{4.36}{84}{Miara G-mean SMOTE z Tomek links.\relax }{table.caption.99}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.6}Por\IeC {\'o}wnanie metod}{84}{subsection.4.3.6}}
\@writefile{lot}{\contentsline {table}{\numberline {4.37}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} klasyfikacji.\relax }}{85}{table.caption.100}}
\newlabel{accporownanie}{{4.37}{85}{Dokładność klasyfikacji.\relax }{table.caption.100}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.38}{\ignorespaces Czu\IeC {\l }o\IeC {\'s}\IeC {\'c} klasy wi\IeC {\k e}kszo\IeC {\'s}ciowej.\relax }}{85}{table.caption.101}}
\newlabel{sensporownanie}{{4.38}{85}{Czułość klasy większościowej.\relax }{table.caption.101}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.39}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej.\relax }}{86}{table.caption.102}}
\newlabel{specporownanie}{{4.39}{86}{Specyficzność klasy mniejszościowej.\relax }{table.caption.102}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.40}{\ignorespaces Miara G-mean.\relax }}{86}{table.caption.103}}
\newlabel{gmeanporownanie}{{4.40}{86}{Miara G-mean.\relax }{table.caption.103}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Propozycja klasyfikator\IeC {\'o}w}{87}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Klasyfikator ekspercki}{87}{section.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Schemat klasyfikatora eksperckiego. $KB_1..KB_i$ to klasyfikatory bazowe.\relax }}{88}{figure.caption.104}}
\newlabel{fig:klasyfikator_ekspercki}{{5.1}{88}{Schemat klasyfikatora eksperckiego. $KB_1..KB_i$ to klasyfikatory bazowe.\relax }{figure.caption.104}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Test klasyfikatora eksperckiego}{88}{subsection.5.1.1}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Dok\IeC {\l }adno\IeC {\'s}\IeC {\'c} klasyfikatora eksperckiego.\relax }}{89}{table.caption.105}}
\newlabel{ekspertacc}{{5.1}{89}{Dokładność klasyfikatora eksperckiego.\relax }{table.caption.105}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Czu\IeC {\l }o\IeC {\'s}\IeC {\'c} klasy wi\IeC {\k e}kszo\IeC {\'s}ciowej dla klasyfikatora eksperckiego.\relax }}{90}{table.caption.106}}
\newlabel{ekspertsens}{{5.2}{90}{Czułość klasy większościowej dla klasyfikatora eksperckiego.\relax }{table.caption.106}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Specyficzno\IeC {\'s}\IeC {\'c} klasy mniejszo\IeC {\'s}ciowej dla klasyfikatora eksperckiego.\relax }}{90}{table.caption.107}}
\newlabel{ekspertspec}{{5.3}{90}{Specyficzność klasy mniejszościowej dla klasyfikatora eksperckiego.\relax }{table.caption.107}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Miara G-mean dla klasyfikatora eksperckiego.\relax }}{91}{table.caption.108}}
\newlabel{ekspertgmean}{{5.4}{91}{Miara G-mean dla klasyfikatora eksperckiego.\relax }{table.caption.108}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Meta-klasyfikator}{91}{section.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Projekt meta-klasyfikatora\relax }}{92}{figure.caption.109}}
\newlabel{fig:metaklasmoj}{{5.2}{92}{Projekt meta-klasyfikatora\relax }{figure.caption.109}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Testy}{92}{subsection.5.2.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Podsumowanie}{93}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{KubatMatwin}{1}
\bibcite{Garcia}{2}
\bibcite{gocardless}{3}
\bibcite{Bishop}{4}
\bibcite{boosting}{5}
\bibcite{uci}{6}
\bibcite{hyper}{7}
\bibcite{StefImbalanced}{8}
\bibcite{przykladyklas}{9}
\bibcite{python}{10}
\bibcite{scikit}{11}
\bibcite{imlearn}{12}
\bibcite{mlxtend}{13}
\@writefile{toc}{\contentsline {chapter}{Bibliografia}{95}{chapter*.110}}
\@writefile{toc}{\contentsline {section}{Spis rysunk\IeC {\'o}w}{98}{chapter*.111}}
\@writefile{toc}{\contentsline {section}{Spis tabel}{101}{chapter*.112}}
